{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6267,"status":"ok","timestamp":1709687474534,"user":{"displayName":"Jing","userId":"13060166029759327333"},"user_tz":300},"id":"J19CLNfgyk-R"},"outputs":[],"source":["import itertools\n","import pandas as pd\n","from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n","from math import sqrt\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.layers import Dense, LSTM, Input, TimeDistributed, RepeatVector, concatenate, Layer\n","from tensorflow.keras.models import Model\n","from tensorflow.keras import regularizers\n","from tensorflow.keras.callbacks import Callback\n","from datetime import datetime\n","import time\n","import pandas as pd\n","from datetime import datetime\n","\n","import ast"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1094,"status":"ok","timestamp":1707841253504,"user":{"displayName":"Jing","userId":"13060166029759327333"},"user_tz":300},"id":"eKe7wWHoymGH","outputId":"fc8752a8-2d5a-4650-b580-c73a87d99e3d"},"outputs":[],"source":["print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n","if tf.test.gpu_device_name():\n","    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n","else:\n","    print(\"Please install GPU version of TF\")\n","\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        # Currently, memory growth needs to be the same across GPUs\n","        for gpu in gpus:\n","            tf.config.experimental.set_memory_growth(gpu, True)\n","        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n","        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","    except RuntimeError as e:\n","        # Memory growth must be set before GPUs have been initialized\n","        print(e)"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":129,"status":"ok","timestamp":1709687482146,"user":{"displayName":"Jing","userId":"13060166029759327333"},"user_tz":300},"id":"yUOHN2Csyoy5"},"outputs":[],"source":["#reset the training and test by time steps\n","def to_supervised(data, space, ts_xandy):\n","    for i in range((len(data))):\n","        cases=data[i,:,:]\n","        list_case=list()\n","        in_start=0\n","        for j in range((len(cases))):\n","            in_end=in_start+ts_xandy\n","            if in_end<=len(cases):\n","                list_case.append(cases[in_start:in_end,:])\n","            in_start+=space\n","        list_case=np.array(list_case)\n","        if i == 0:\n","            final=list_case\n","        else:\n","            final=np.vstack((final,list_case))\n","    return final\n","\n","\n","#process the data\n","def process_data (ph, space, df_all_o, list_colmns, number_location_static):\n","    ti=5 #time interval\n","    begining_time=65 #from 60 minutes before incident happens\n","\n","    number_of_ti=4*60/ti#evevry case how many time steps\n","    start=int((65-begining_time)/ti)\n","    end=int(number_of_ti) #the mamximun time step that this model can predict\n","    ts_xandy=int((begining_time+ph)/ti)\n","    split_y=int(begining_time/ti)\n","\n","\n","    df_all=df_all_o.loc[:,list_colmns]\n","    df_all=df_all.reset_index(drop=True)\n","\n","    #make sure no missing data\n","    for i in df_all.columns:\n","        se=df_all[i].copy()\n","        index_outliers=se[abs(se-se.mean())>4*se.std()].index.to_list()\n","        se.iloc[index_outliers]=np.nan\n","        df_all[i]=se\n","    df_all=df_all.fillna(method=\"backfill\")\n","    nan_df=pd.isna(df_all).sum()\n","\n","    #scale x, standerdization\n","    df_nospeed=df_all.iloc[:,1:]\n","    df_nospeed=(df_nospeed-df_nospeed.mean())/df_nospeed.std()\n","    df_model=df_nospeed.copy()\n","    speed=df_all['speed']\n","    df_model['speed']=speed\n","\n","\n","    df_model=df_model.loc[:,list_colmns]\n","\n","    #sequence of speed y\n","    or_speed=0\n","\n","    #split training, validation, test\n","    values=df_model.values\n","    values = np.array(np.split(values, len(values)/number_of_ti))\n","    values=values[:,start:end,:]\n","\n","    #split training and test\n","    np.random.seed(688)\n","    indices = np.random.permutation(values.shape[0])\n","    num_train=int(values.shape[0]*0.7)\n","    training_idx, test_idx = indices[:num_train], indices[num_train:]\n","\n","    training, test = values[training_idx,:], values[test_idx,:]\n","\n","    training_su=to_supervised(training, space, ts_xandy)\n","    test_su=to_supervised(test, space, ts_xandy)\n","\n","    #split x,y\n","\n","    training_x, training_y=training_su[:,:split_y,:], training_su[:,split_y:,or_speed]\n","    test_x,test_y=test_su[:,:split_y,:], test_su[:,split_y:,or_speed]\n","\n","\n","    sequential_input_data=training_x[:,:,:number_location_static]\n","    static_input_data=training_x[:,0,number_location_static:]\n","    output_data=training_y\n","\n","    test_sequ_input=test_x[:,:,:number_location_static]\n","    test_sta_input=test_x[:,0,number_location_static:]\n","    test_output=test_y\n","\n","\n","    static_input_dim=static_input_data.shape[1]\n","\n","    n_timesteps=sequential_input_data.shape[1]\n","    seq_input_dim=sequential_input_data.shape[2]\n","\n","    output_dim=output_data.shape[1]\n","\n","    return (sequential_input_data, static_input_data, output_data,\n","            test_sequ_input, test_sta_input, test_output,\n","            static_input_dim, n_timesteps, seq_input_dim, output_dim,\n","            test,ts_xandy, split_y, test_idx, training, training_idx)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gSN_W7IwypH1"},"outputs":[],"source":["#new test and training accuracy\n","\n","def performance (model, test, ts_xandy, split_y, test_idx):\n","  performance_each_test=pd.DataFrame(columns=['number','MAPE','RMSE','MAE'])\n","  for i in range(len(test)):\n","      #make sure i's shape is (1,48,7)\n","      test_i=test[i,:,:]\n","      test_i=test_i.reshape(1,test_i.shape[0],test_i.shape[1])\n","\n","      test_su=to_supervised(test_i, space, ts_xandy)\n","\n","      test_x,test_y=test_su[:,:split_y,:], test_su[:,split_y:,0]\n","\n","      test_sequ_input=test_x[:,:,:number_location_static]\n","      test_sta_input=test_x[:,0,number_location_static:]\n","      test_output=test_y\n","\n","      ythat=model.predict([test_sta_input, test_sequ_input], verbose=0, )\n","      ythat=ythat.reshape(ythat.shape[0],ythat.shape[1])\n","\n","      mape_test=mean_absolute_percentage_error(test_y, ythat)\n","      rmse_test = sqrt(mean_squared_error(test_y, ythat))\n","      #caculate MAE\n","      mae_test=np.mean(np.abs(test_y-ythat))\n","\n","\n","      performance_each_test.loc[i]=[i,mape_test,rmse_test,mae_test]\n","\n","  #add test index in performance_each_test\n","  performance_each_test['test_index']=test_idx\n","  return performance_each_test\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sW6i6AiVyx8v"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.layers import Layer\n","\n","\n","class BahdanauAttentionLayer(Layer):\n","    def __init__(self, attention_dim, **kwargs):\n","\n","        self.attention_dim = attention_dim\n","        super(BahdanauAttentionLayer, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        self.W1 = self.add_weight(\n","            name='attention_weight1',\n","            shape=(input_shape[-1], self.attention_dim),\n","            initializer='random_normal',\n","            trainable=True\n","        )\n","        self.W2 = self.add_weight(\n","            name='attention_weight2',\n","            shape=(input_shape[-1], self.attention_dim),\n","            initializer='random_normal',\n","            trainable=True\n","        )\n","        self.V = self.add_weight(\n","            name='attention_value',\n","            shape=(self.attention_dim, 1),\n","            initializer='random_normal',\n","            trainable=True\n","        )\n","        super(BahdanauAttentionLayer, self).build(input_shape)\n","\n","    def call(self, x):\n","        query_with_time_axis = tf.expand_dims(x[:, -1, :], 1)  # Last hidden state as the query\n","\n","        # Custom scoring function with adjusted dimensions\n","        score = tf.nn.tanh(tf.matmul(query_with_time_axis, self.W1) + tf.matmul(x, self.W2))\n","        alignment_scores = tf.matmul(score, self.V)\n","\n","        # Softmax to get the attention weights\n","        attention_weights = tf.nn.softmax(alignment_scores, axis=1)\n","\n","        # Context vector\n","        context_vector = attention_weights * x\n","        context_vector = tf.reduce_sum(context_vector, axis=1)\n","\n","        return context_vector\n","\n","    def get_config(self):\n","        config = super(BahdanauAttentionLayer, self).get_config()\n","        config['attention_dim'] = self.attention_dim\n","        return config\n","\n","\n","#set the model structure\n","def define_model(static_input_dim, n_timesteps, seq_input_dim, output_dim,\n","                 encodedecode_neurons, reg_technique, optimizer, activation,\n","                 learning_rate, dropout_rate, attention_type):\n","    # Regularization\n","    if reg_technique is not None:\n","        if reg_technique == 'l1(0.01)':\n","            reg = regularizers.l1(l=0.01)\n","    else:\n","        reg = None\n","\n","    # Static branch\n","    inputA = Input(shape=(static_input_dim,))\n","    layer1 = Dense(encodedecode_neurons*4, activation=activation, kernel_regularizer=reg)(inputA)\n","    layer2 = Dense(encodedecode_neurons*2, activation=activation, kernel_regularizer=reg)(layer1)\n","\n","\n","    xstatic = Model(inputs=inputA, outputs=layer2)\n","\n","    # Sequence branch\n","    input_layer = Input(shape=(n_timesteps, seq_input_dim))\n","    x = LSTM(encodedecode_neurons*8, activation=activation, return_sequences=True, kernel_regularizer=reg)(input_layer)\n","    x = LSTM(encodedecode_neurons*4, activation=activation, return_sequences=True, kernel_regularizer=reg)(x)\n","    x = LSTM(encodedecode_neurons*2, activation=activation, return_sequences=True, kernel_regularizer=reg)(x)\n","    x = LSTM(encodedecode_neurons*2, activation=activation, return_sequences=True, kernel_regularizer=reg)(x)\n","    x = LSTM(encodedecode_neurons, activation=activation, return_sequences=True, kernel_regularizer=reg)(x)\n","    x = LSTM(encodedecode_neurons, activation=activation, return_sequences=True, kernel_regularizer=reg)(x)\n","\n","    # Attention layer\n","    if attention_type == 'bahdanau':\n","        attention = BahdanauAttentionLayer(attention_dim=64)(x)  # Assuming BahdanauAttentionLayer is defined elsewhere\n","\n","\n","    x = Model(inputs=input_layer, outputs=attention)\n","\n","    # Combining the outputs\n","    combined = concatenate([xstatic.output, x.output])\n","\n","    # Repeat vector layer\n","    combined = RepeatVector(output_dim)(combined)\n","    combined = LSTM(encodedecode_neurons, activation=activation, return_sequences=True)(combined)\n","\n","\n","\n","    # Time distributed dense layers\n","    z = TimeDistributed(Dense(encodedecode_neurons, activation=activation))(combined)\n","    z = TimeDistributed(Dense(1))(z)\n","\n","    # Final model\n","    if optimizer == 'adam':\n","        opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n","    elif optimizer == 'sgd':\n","        opt = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n","    elif optimizer == 'rmsprop':\n","        opt = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n","    elif optimizer == 'adagrad':\n","        opt = tf.keras.optimizers.Adagrad(learning_rate=learning_rate)\n","    elif optimizer == 'adadelta':\n","        opt = tf.keras.optimizers.Adadelta(learning_rate=learning_rate)\n","    elif optimizer == 'adamax':\n","        opt = tf.keras.optimizers.Adamax(learning_rate=learning_rate)\n","    # ... Add other optimizers similarly\n","    elif optimizer == 'nadam':\n","        opt = tf.keras.optimizers.Nadam(learning_rate=learning_rate)\n","\n","    model = Model(inputs=[xstatic.input, x.input], outputs=z)\n","    model.compile(optimizer=opt, loss='mse', metrics=[tf.keras.metrics.MeanAbsolutePercentageError()])\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Placeholder for results\n","results = []\n","\n","file_path='data.xlsx'\n","df_all_o = pd.read_excel(file_path)\n","\n","list_colmns=['speed','flow','std_flow','std_speed',\n","             'distance','NOL','severity',]\n","list_per=['MAPE','RMSE','MAE']\n","number_location_static=4\n","#set epochs\n","epochs=30\n","#set the params\n","params=(2,None, 'adam', 'tanh', 16, 0.001, 0, 'bahdanau',15)\n","space, reg_technique, optimizer, activation, encodedecode_neurons, learning_rate, dropout_rate, attention_type,ph = params\n","\n","(sequential_input_data, static_input_data,\n","    output_data,test_sequ_input, test_sta_input,\n","    test_output,static_input_dim, n_timesteps,\n","    seq_input_dim, output_dim,test,ts_xandy,\n","    split_y, test_idx, training,training_idx)= process_data (ph, space,df_all_o, list_colmns, number_location_static)\n","\n","# Define and compile your model\n","model = define_model(static_input_dim, n_timesteps, seq_input_dim, output_dim,\n","                        encodedecode_neurons, reg_technique, optimizer, activation,\n","                        learning_rate, dropout_rate, attention_type)\n","start_time = time.time()\n","# Train the model\n","history = model.fit([static_input_data, sequential_input_data], output_data, \n","                    epochs=epochs, validation_split=0.25)\n","# End the timer\n","end_time = time.time()\n","# Calculate the elapsed time\n","elapsed_time = (end_time - start_time)/epochs\n","\n","\n","perf_test_df=performance (model, test, ts_xandy, split_y, test_idx)\n","this_test=perf_test_df[list_per].mean()\n","\n","print(this_test)\n","print(elapsed_time)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyP1sdFeP1WOfzgxUwoX3gwe","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":0}
